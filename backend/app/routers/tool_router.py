# backend/app/routers/tool_router.py
from __future__ import annotations

import os, re, json, time, threading, logging, requests
from typing import List, Dict, Optional, Tuple
from datetime import datetime, timezone
from urllib.parse import urlparse

from fastapi import APIRouter, Depends, Query
from sqlalchemy.orm import Session

from app.db.database import get_db
from app.models.tool import AITool
from app.schemas.tool_schema import PlanRequest, PlanResponse

# ---------- Ð›Ð¾Ð³ÐµÑ€ ----------
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

# ---------- LLM (Groq) ----------
GROQ_API_URL = "https://api.groq.com/openai/v1/chat/completions"
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
if not GROQ_API_KEY:
    logger.warning("GROQ_API_KEY Ð»Ð¸Ð¿ÑÐ²Ð° â€“ Ñ‰Ðµ ÑÐµ Ð¿Ð¾Ð»Ð·Ð²Ð°Ñ‚ ÑÑ‚Ð°Ñ‚Ð¸Ñ‡Ð½Ð¸ fallback ÑÑ‚ÑŠÐ¿ÐºÐ¸.")

SUPPORTED_MODELS = [
    "llama3-70b-8192",
    "llama3-8b-8192",
    "llama-3.1-8b-instant",
    "llama-3.3-70b-versatile",
    "gemma2-9b-it",
]

router = APIRouter()

# =========================================================
#                  Ð˜ Ð Ð” Ð• Ðš Ð¡ Ð˜  /  Ð• Ðœ Ð‘ Ð• Ð” Ð˜ Ð Ð“
# =========================================================
try:
    import faiss
    _HAS_FAISS = True
except Exception:
    _HAS_FAISS = False

from sentence_transformers import SentenceTransformer
from rapidfuzz import fuzz
import numpy as np

EMBED_MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
_embed_model: Optional[SentenceTransformer] = None

_faiss_index = None
_emb_matrix: Optional[np.ndarray] = None
_tool_texts: List[str] = []
_tool_objs: List[AITool] = []
_index_lock = threading.Lock()

tools_by_tag: Dict[str, List[AITool]] = {}
tools_cache_lock = threading.Lock()


def _load_embed_model():
    global _embed_model
    if _embed_model is None:
        logger.info(f"ðŸ§  Ð—Ð°Ñ€ÐµÐ¶Ð´Ð°Ð¼ embedding Ð¼Ð¾Ð´ÐµÐ»: {EMBED_MODEL_NAME}")
        _embed_model = SentenceTransformer(EMBED_MODEL_NAME)


def _to_unit(vecs: np.ndarray) -> np.ndarray:
    norms = np.linalg.norm(vecs, axis=1, keepdims=True) + 1e-12
    return vecs / norms


def build_tool_index(db: Session):
    """Ð˜Ð½Ð´ÐµÐºÑ Ð¿Ð¾ Ñ‚Ð°Ð³Ð¾Ð²Ðµ (cap:* Ð¸ Ð´Ñ€.)."""
    global tools_by_tag
    with tools_cache_lock:
        tools_by_tag.clear()
        for t in db.query(AITool).all():
            for tag in (t.tags or []):
                k = (tag or "").lower().strip()
                if not k:
                    continue
                tools_by_tag.setdefault(k, []).append(t)
    logger.info(f"ðŸ§° Ð˜Ð½Ð´ÐµÐºÑ Ð¿Ð¾ Ñ‚Ð°Ð³Ð¾Ð²Ðµ Ð³Ð¾Ñ‚Ð¾Ð²: {len(tools_by_tag)} ÐºÐ»ÑŽÑ‡Ð°")


def build_semantic_index(db: Session):
    """Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÐ½ Ð¸Ð½Ð´ÐµÐºÑ Ð²ÑŠÑ€Ñ…Ñƒ (name + tags)."""
    global _faiss_index, _emb_matrix, _tool_texts, _tool_objs
    _load_embed_model()

    with _index_lock:
        _tool_texts, _tool_objs = [], []
        tools = db.query(AITool).all()
        for t in tools:
            _tool_texts.append(f"{t.name}. Tags: {', '.join(t.tags or [])}")
            _tool_objs.append(t)

        if not _tool_texts:
            _faiss_index, _emb_matrix = None, None
            return

        emb = _embed_model.encode(_tool_texts, convert_to_numpy=True, show_progress_bar=False)
        emb = _to_unit(emb).astype(np.float32)

        if _HAS_FAISS:
            _faiss_index = faiss.IndexFlatIP(emb.shape[1])
            _faiss_index.add(emb)
            _emb_matrix = None
        else:
            _faiss_index = None
            _emb_matrix = emb


def _semantic_candidates(query: str, top_k: int = 16) -> List[Tuple[AITool, float]]:
    if not _tool_texts:
        return []
    q_emb = _embed_model.encode([query], convert_to_numpy=True, show_progress_bar=False)
    q_emb = _to_unit(q_emb).astype(np.float32)
    if _faiss_index is not None:
        D, I = _faiss_index.search(q_emb, min(top_k, len(_tool_texts)))
        idxs, sims = I[0], D[0]
        out: List[Tuple[AITool, float]] = []
        for i, s in zip(idxs, sims):
            if i < 0:
                continue
            out.append((_tool_objs[i], float(s)))
        return out
    sims = (_emb_matrix @ q_emb.T).ravel()
    idxs = np.argsort(-sims)[:top_k]
    return [(_tool_objs[i], float(sims[i])) for i in idxs]


def _cap_candidates(cap: str, db: Session, per_cap: int = 16) -> List[AITool]:
    cap = (cap or "").lower().strip()
    bucket = tools_by_tag.get(cap, [])
    if bucket:
        return bucket[:per_cap]
    # fallback: fuzzy Ð² Ñ‚Ð°Ð³Ð¾Ð²Ðµ
    out: List[Tuple[AITool, int]] = []
    for t in db.query(AITool).all():
        best = max((fuzz.partial_ratio(cap, (tag or "").lower()) for tag in (t.tags or [])), default=0)
        if best >= 75:
            out.append((t, best))
    out.sort(key=lambda x: -x[1])
    return [t for (t, _) in out[:per_cap]]

# =========================================================
#              Ð  Ð• Ð™ Ð¢ Ð˜ Ð Ð“ Ð˜  /  ÐŸ Ðž ÐŸ Ð£ Ð› Ð¯ Ð  Ð Ðž Ð¡ Ð¢
# =========================================================
CORE_UNIVERSAL = {"ChatGPT", "Claude", "Microsoft Copilot", "Gemini", "Perplexity", "Groq"}

POPULARITY_PRIOR: Dict[str, float] = {
    "ChatGPT": 1.00, "Claude": 0.98, "Microsoft Copilot": 0.95, "Gemini": 0.93, "Perplexity": 0.94, "Groq": 0.92,
    "Midjourney": 0.90, "DALLÂ·E 3": 0.88, "Stable Diffusion": 0.86, "Runway": 0.87, "Descript": 0.83, "CapCut": 0.84,
    "Zapier Agents": 0.86, "n8n": 0.84, "Make.com": 0.83, "Canva AI": 0.86, "Gamma": 0.84, "Tome": 0.83,
}

DEPRIORITIZE_FOR_LEARNING = {"NotebookLM", "Chatbase", "Botsonic"}

AA_URL = "https://artificialanalysis.ai/leaderboards/models"
LIVE_RATINGS_ENABLED = os.getenv("LIVE_RATINGS_ENABLED", "true").lower() == "true"
RATINGS_TTL_SEC = int(os.getenv("RATINGS_TTL_SEC", str(60 * 60 * 6)))      # 6h
RATINGS_FAIL_RETRY_SEC = int(os.getenv("RATINGS_FAIL_RETRY_SEC", "600"))   # 10m backoff
RATINGS_TIMEOUT_SEC = float(os.getenv("RATINGS_TIMEOUT_SEC", "5"))

_RATINGS_CACHE: Dict[str, float] = {}
_RATINGS_TS: float = 0.0
_RATINGS_OK: bool = False
_RATINGS_LOCK = threading.Lock()

ALIASES = {
    "GPT-4": "ChatGPT", "GPT-4o": "ChatGPT", "GPT-4.1": "ChatGPT", "GPT-3.5": "ChatGPT",
    "Claude 3": "Claude", "Claude 3.5": "Claude", "Claude 2": "Claude",
    "Gemini Advanced": "Gemini", "Gemini 1.5": "Gemini",
    "Llama": "Groq",  # Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÐ½ alias Ð·Ð° OSS/hosted Ð»Ð¸Ð½Ð¸Ð¸
}

def _norm_name(name: str) -> str:
    return ALIASES.get((name or "").strip(), (name or "").strip())


def _parse_aa_html(html: str) -> Dict[str, float]:
    m = re.search(r'<script id="__NEXT_DATA__"[^>]*>(.*?)</script>', html, flags=re.S)
    data = None
    if m:
        try:
            data = json.loads(m.group(1))
        except Exception:
            data = None
    scores: Dict[str, float] = {}

    def add(name: str, v: float):
        n = _norm_name(name)
        if v > 1: v = v / 100.0
        scores[n] = max(scores.get(n, 0.0), float(max(0.0, min(1.0, v))))

    if data:
        dump = json.dumps(data)
        for m2 in re.finditer(r'"name"\s*:\s*"([^"]+)"[^\}]{0,400}?"score"\s*:\s*(\d+(?:\.\d+)?)', dump):
            add(m2.group(1), float(m2.group(2)))
        for m2 in re.finditer(r'"model"\s*:\s*"([^"]+)"[^\}]{0,400}?"(overall|rating|avg)"\s*:\s*(\d+(?:\.\d+)?)', dump):
            add(m2.group(1), float(m2.group(3)))
    if not scores:
        for m3 in re.finditer(r'"(model|name)"\s*:\s*"([^"]+)"[^\}]{0,200}?"(score|rating|overall)"\s*:\s*(\d+(?:\.\d+)?)', html):
            add(m3.group(2), float(m3.group(4)))
    return scores


def _should_skip_fetch(now: float, force: bool) -> bool:
    if force: return False
    if not LIVE_RATINGS_ENABLED: return True
    if _RATINGS_TS == 0.0: return False
    age = now - _RATINGS_TS
    limit = RATINGS_TTL_SEC if _RATINGS_OK else RATINGS_FAIL_RETRY_SEC
    return age < limit


def _fetch_ratings(force: bool = False) -> Dict[str, float]:
    global _RATINGS_CACHE, _RATINGS_TS, _RATINGS_OK
    with _RATINGS_LOCK:
        now = time.time()
        if _should_skip_fetch(now, force):
            return dict(_RATINGS_CACHE)

        if not LIVE_RATINGS_ENABLED:
            _RATINGS_TS, _RATINGS_OK = now, False
            return dict(_RATINGS_CACHE)

        try:
            logger.info("â¬‡ï¸ Ð¢ÐµÐ³Ð»Ñ live Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³Ð¸ Ð¾Ñ‚ artificialanalysis.aiâ€¦")
            r = requests.get(AA_URL, timeout=RATINGS_TIMEOUT_SEC)
            r.raise_for_status()
            scores = _parse_aa_html(r.text)
            _RATINGS_TS = now
            if scores:
                _RATINGS_CACHE, _RATINGS_OK = scores, True
                logger.info(f"âœ… Ð—Ð°Ñ€ÐµÐ´ÐµÐ½Ð¸ {len(scores)} Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³Ð°")
            else:
                _RATINGS_CACHE, _RATINGS_OK = {}, False
                logger.warning("âš ï¸ ÐÐµ ÑƒÑÐ¿ÑÑ… Ð´Ð° Ð¸Ð·Ð²Ð»ÐµÐºÐ° Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³Ð¸ â€“ Ð¿Ð¾Ð»Ð·Ð²Ð°Ð¼ fallback prior-Ð¸.")
        except Exception as e:
            _RATINGS_TS, _RATINGS_CACHE, _RATINGS_OK = now, {}, False
            logger.warning("âš ï¸ ÐÐµ ÑƒÑÐ¿ÑÑ… Ð´Ð° Ð¸Ð·Ð²Ð»ÐµÐºÐ° Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³Ð¸ â€“ Ð¿Ð¾Ð»Ð·Ð²Ð°Ð¼ fallback prior-Ð¸. (%s)", str(e))
        return dict(_RATINGS_CACHE)


def get_all_ratings() -> Dict[str, float]:
    return _fetch_ratings(force=False)


def get_model_rating01(model: str) -> float:
    data = get_all_ratings()
    return float(data.get(_norm_name(model), 0.0))


@router.post("/ratings/refresh")
def refresh_ratings():
    data = _fetch_ratings(force=True)
    return {"ok": _RATINGS_OK, "count": len(data)}

@router.get("/ratings/health")
def ratings_health():
    now = time.time()
    age = now - _RATINGS_TS if _RATINGS_TS else None
    last = datetime.fromtimestamp(_RATINGS_TS, tz=timezone.utc).isoformat() if _RATINGS_TS else None
    return {
        "ok": _RATINGS_OK, "count": len(_RATINGS_CACHE), "last_refresh": last,
        "age_seconds": int(age) if age is not None else None,
        "source": "live" if _RATINGS_OK and _RATINGS_CACHE else "fallback",
        "enabled": LIVE_RATINGS_ENABLED,
    }

# =========================================================
#               Ðš Ð ÐŸ Ð Ð‘ Ð˜ Ð› Ð˜ Ð¢ Ð˜  /  Ðœ Ð ÐŸ Ð˜ Ð Ð“
# =========================================================
CAP_PHRASE = {
    "cap:research-web": "ÐÐ°Ð¼ÐµÑ€Ð¸ Ð½Ð°Ð´ÐµÐ¶Ð´Ð½Ð¸ Ð¸Ð·Ñ‚Ð¾Ñ‡Ð½Ð¸Ñ†Ð¸ Ð¸ Ð¿Ñ€ÐµÐ³Ð»ÐµÐ´Ð¸",
    "cap:text-explain": "ÐžÐ±ÑÑÐ½Ð¸ Ð¸ Ð¾Ñ‚Ð³Ð¾Ð²Ð¾Ñ€Ð¸ Ð½Ð° Ð²ÑŠÐ¿Ñ€Ð¾ÑÐ¸",
    "cap:text-summarize": "Ð ÐµÐ·ÑŽÐ¼Ð¸Ñ€Ð°Ð¹ ÑÑ‚Ð°Ñ‚Ð¸Ð¸/Ð²Ð¸Ð´ÐµÐ°/Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¸",
    "cap:doc-read-pdf": "Ð§ÐµÑ‚Ð¸/Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð°Ð¹ PDF/Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¸",
    "cap:slide-generate": "ÐÐ°Ð¿Ñ€Ð°Ð²Ð¸ ÐºÑ€Ð°Ñ‚ÐºÐ¾ Ð¾Ð±Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ/ÑÐ»Ð°Ð¹Ð´Ð¾Ð²Ðµ",
    "cap:image-generate": "Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€Ð°Ð¹ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¸ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸",
    "cap:image-edit": "Ð ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð°Ð¹ Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ",
    "cap:video-generate": "Ð¡ÑŠÐ·Ð´Ð°Ð¹/Ð·Ð°ÑÐ½ÐµÐ¼Ð¸ Ð²Ð¸Ð´ÐµÐ¾ ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸Ðµ",
    "cap:video-edit": "ÐœÐ¾Ð½Ñ‚Ð¸Ñ€Ð°Ð¹ Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð¸ Ð²Ð¸Ð´ÐµÐ¾",
    "cap:automate-workflow": "ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð¸Ñ€Ð°Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑÐ¸ Ð¸ Ð·Ð°Ð´Ð°Ñ‡Ð¸",
    "cap:integrations": "Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð¸Ñ€Ð°Ð¹ Ñ Ð¿Ð»Ð°Ñ‚Ñ„Ð¾Ñ€Ð¼Ð¸ Ð¸ ÑƒÑÐ»ÑƒÐ³Ð¸",
}

CAPS_LEARNING_DISCOVER   = ["cap:research-web", "cap:text-explain"]
CAPS_LEARNING_MATERIALS  = ["cap:research-web", "cap:text-summarize", "cap:doc-read-pdf"]
CAPS_LEARNING_PRACTICE   = ["cap:text-explain", "cap:slide-generate"]

def _favicon_from_website(website: Optional[str], size: int = 64) -> Optional[str]:
    if not website:
        return None
    domain = urlparse(website).netloc or website
    return f"https://www.google.com/s2/favicons?domain={domain}&sz={size}"

def _tool_icon(t: AITool) -> Optional[str]:
    icon_db = getattr(t, "icon_url", None)
    if icon_db:
        return icon_db
    website = (t.links or {}).get("website")
    return _favicon_from_website(website)

# =========================================================
#                Ð¡ Ðš Ðž Ð  Ð˜ Ð Ð“  /  Ð  Ð• Ðš Ðž Ðœ Ð• Ð Ð” Ð Ð¦ Ð˜ Ð˜
# =========================================================
def _is_learning_query(goal: str) -> bool:
    return bool(re.search(r"\b(ÑƒÑ‡Ð¸|Ð½Ð°ÑƒÑ‡Ð¸|Ð½Ð°ÑƒÑ‡Ð°|Ð¾Ð±ÑÑÐ½Ð¸|ÐºÐ°ÐºÐ²Ð¾ Ðµ|what is|learn|course|ÐºÑƒÑ€Ñ|scrum|agile)\b", goal, flags=re.I))

def _score_tool(t: AITool, goal: str, step: str, cap: Optional[str], semantic_query: str) -> float:
    name = t.name
    live = get_model_rating01(name)  # 0..1 Ð°ÐºÐ¾ Ð¸Ð¼Ð°; Ð¸Ð½Ð°Ñ‡Ðµ 0
    prior = POPULARITY_PRIOR.get(name, 0.5)

    tag_bonus = 0.0
    if cap and any(cap == (tag or "").lower().strip() for tag in (t.tags or [])):
        tag_bonus = 0.06

    # ÐµÐ²Ñ‚Ð¸Ð½ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÐ½ Ð±Ð¾Ð½ÑƒÑ Ñ fuzzy (Ð¸Ð·Ð±ÑÐ³Ð²Ð°Ð¼Ðµ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð½Ð¾ embed)
    sem_sim = 0.0
    try:
        sem_sim = fuzz.partial_ratio(
            f"{semantic_query} {goal}".lower(),
            f"{t.name} {' '.join(t.tags or [])}".lower()
        ) / 100.0
    except Exception:
        pass

    score = (0.58 * max(live, prior)) + (0.27 * sem_sim) + (0.15 * tag_bonus)
    if _is_learning_query(goal) and name in DEPRIORITIZE_FOR_LEARNING:
        score -= 0.15
    return float(score)


def re_rank_tools(
    candidates: List[AITool],
    goal: str,
    step: str,
    cap: Optional[str],
    semantic_query: str,
    top_n: int = 6,
    ensure_universal_top3: bool = False,
    db: Optional[Session] = None,
) -> List[Dict]:
    uniq: Dict[str, AITool] = {t.name: t for t in candidates if t and t.name}
    scored: List[Tuple[float, AITool]] = [(_score_tool(t, goal, step, cap, semantic_query), t) for t in uniq.values()]
    scored.sort(key=lambda x: -x[0])

    out: List[Dict] = [{"name": t.name,
                        "link": (t.links or {}).get("website"),
                        "icon": _tool_icon(t)} for (_s, t) in scored[:top_n]]

    # Ð°ÐºÐ¾ Ñ‚Ñ€ÑÐ±Ð²Ð° â€“ Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ€Ð°Ð½Ð¾ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ°Ð»ÐµÐ½ Ð² Ñ‚Ð¾Ð¿â€‘3 (Ð±ÐµÐ· Ð´Ð° Ð³ÑƒÐ±Ð¸Ð¼ Ð°Ð»Ñ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð¸)
    if ensure_universal_top3 and not any(x["name"] in CORE_UNIVERSAL for x in out[:3]):
        for n in ["ChatGPT", "Claude", "Microsoft Copilot", "Perplexity", "Gemini", "Groq"]:
            q = db.query(AITool).filter(AITool.name == n).first() if db else None
            if q:
                uni = {"name": q.name, "link": (q.links or {}).get("website"), "icon": _tool_icon(q)}
                out = ([uni] + out)[:top_n]
                break

    # Ð»ÐµÐºÐ¾ Ñ€Ð°Ð·Ð½Ð¾Ð¾Ð±Ñ€Ð°Ð·Ð¸Ðµ: Ð°ÐºÐ¾ Ñ‚Ð¾Ð¿â€‘3 ÑÐ° ÑÐ°Ð¼Ð¾ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ°Ð»Ð¸, Ð¿Ð¾Ð´ÑÐ¸Ð³ÑƒÑ€Ð¸ Ð¸ 1â€“2 Ð°Ð»Ñ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð¸ Ð² Ñ‚Ð¾Ð¿â€‘6
    if len([x for x in out[:3] if x["name"] in CORE_UNIVERSAL]) >= 2:
        # Ð¾Ð¿Ð¸Ñ‚Ð°Ð¹ Ð´Ð° Ð´Ð¾Ð±Ð°Ð²Ð¸Ñˆ Ð½Ðµâ€‘ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ°Ð»Ð½Ð¸ Ð¾Ñ‚ Ð¾ÑÑ‚Ð°Ñ‚ÑŠÐºÐ°
        extras = [x for x in out[3:] if x["name"] not in CORE_UNIVERSAL][:2]
        out = out[:4] + extras + out[4+len(extras):]
        out = out[:top_n]

    return out

# =========================================================
#             Ðš Ð Ð Ðž Ð Ð˜ Ð§ Ð Ð˜  Ð¡ Ð¢ Ðª ÐŸ Ðš Ð˜  (LEARNING)
# =========================================================
LEARNING_CANONICAL = [
    ("ÐžÑ‚ÐºÑ€Ð¸Ð¹ ÐºÐ°ÐºÐ²Ð¾ Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²Ð»ÑÐ²Ð° Ñ‚ÐµÐ¼Ð°Ñ‚Ð° Ð¸ Ð·Ð°Ñ‰Ð¾ Ðµ Ð²Ð°Ð¶Ð½Ð°", CAPS_LEARNING_DISCOVER),
    ("ÐÐ°Ð¼ÐµÑ€Ð¸ Ð¸ Ð¾Ñ€Ð³Ð°Ð½Ð¸Ð·Ð¸Ñ€Ð°Ð¹ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð¸ Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð»Ð¸ Ð·Ð° Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ", CAPS_LEARNING_MATERIALS),
    ("ÐŸÑ€Ð°ÐºÑ‚Ð¸ÐºÑƒÐ²Ð°Ð¹, Ð¾Ð±Ð¾Ð±Ñ‰Ð¸ Ð¸ Ð¿Ð¸Ñ‚Ð°Ð¹ Ð·Ð° Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð° Ð²Ñ€ÑŠÐ·ÐºÐ°", CAPS_LEARNING_PRACTICE),
]

def _learning_plan(goal: str, db: Session) -> Tuple[List[Dict], List[Dict]]:
    """
    Ð’Ñ€ÑŠÑ‰Ð° 3 Ð¾Ð±Ð¾Ð±Ñ‰ÐµÐ½Ð¸ ÑÑ‚ÑŠÐ¿ÐºÐ¸ Ð·Ð° ÑƒÑ‡ÐµÐ½Ðµ + Ð³Ñ€ÑƒÐ¿Ð¸ Ð·Ð° UI.
    Ð’ÑŠÐ² Ð²ÑÑÐºÐ° ÑÑ‚ÑŠÐ¿ÐºÐ°: Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ€Ð°Ð¼Ðµ ÑÐ¸Ð»Ð½Ð¸ ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ°Ð»Ð¸ + ÑÐ¼Ð¸ÑÐ»ÐµÐ½Ð¸ Ð°Ð»Ñ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð¸.
    """
    plan: List[Dict] = []
    for (task, caps) in LEARNING_CANONICAL:
        # ÑÑŠÐ±Ð¸Ñ€Ð°Ð½Ðµ Ð½Ð° ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚Ð¸
        candidates: List[AITool] = []
        for cap in caps:
            candidates += _cap_candidates(cap, db, per_cap=16)
        if not candidates:
            # Ð·Ð° Ð²ÑÐµÐºÐ¸ ÑÐ»ÑƒÑ‡Ð°Ð¹ â€“ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸ÐºÐ° Ð¿Ð¾ Ñ‚ÐµÐºÑÑ‚Ð° Ð½Ð° ÑÑ‚ÑŠÐ¿ÐºÐ°Ñ‚Ð°
            candidates = [t for (t, _s) in _semantic_candidates(task, top_k=16)]

        cap_for_rank = caps[0] if caps else None
        tools = re_rank_tools(
            candidates=candidates,
            goal=goal,
            step=task,
            cap=cap_for_rank,
            semantic_query=task,
            top_n=6,
            ensure_universal_top3=True,
            db=db,
        )

        # ÑÐ²Ð¸Ð²Ð°Ð¼Ðµ Ð´Ð¾ 3 Ð·Ð° Ð¿Ð¾â€‘Ñ‡Ð¸ÑÑ‚ UI
        tools = tools[:3] if len(tools) > 3 else tools
        if not tools:
            tools = [{"name": "ChatGPT", "link": "https://chat.openai.com/", "icon": None}]
        plan.append({"task": task, "tools": tools})

    groups = [{"title": item["task"], "tools": item["tools"]} for item in plan]
    return plan, groups

# =========================================================
#                 T E M P L A T E S  (Ð´Ñ€ÑƒÐ³Ð¸ Ñ†ÐµÐ»Ð¸)
# =========================================================
TEMPLATES = [
    {
        "name": "music_video",
        "match": r"\b(Ð¼ÑƒÐ·Ð¸ÐºÐ°Ð»ÐµÐ½\s+ÐºÐ»Ð¸Ð¿|music\s+video|Ð²Ð¸Ð´ÐµÐ¾ÐºÐ»Ð¸Ð¿|ÐºÐ»Ð¸Ð¿)\b",
        "steps": [
            ("Ð Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ð¸ ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ Ð¸ Ð½Ð°Ð¿Ð¸ÑˆÐ¸ ÑÑ†ÐµÐ½Ð°Ñ€Ð¸Ð¹", ["cap:text-explain", "cap:image-generate"]),
            ("ÐžÑ€Ð³Ð°Ð½Ð¸Ð·Ð¸Ñ€Ð°Ð¹ ÑÐ½Ð¸Ð¼Ð°Ñ‡ÐµÐ½ ÐµÐºÐ¸Ð¿ Ð¸ Ð»Ð¾ÐºÐ°Ñ†Ð¸Ð¸", ["cap:research-web", "cap:automate-workflow"]),
            ("Ð—Ð°ÑÐ½ÐµÐ¼Ð¸ Ð²Ð¸Ð´ÐµÐ¾ Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð»Ð°", ["cap:video-generate"]),
            ("ÐœÐ¾Ð½Ñ‚Ð¸Ñ€Ð°Ð¹ ÐºÐ»Ð¸Ð¿Ð° Ð¸ Ð´Ð¾Ð±Ð°Ð²Ð¸ ÐµÑ„ÐµÐºÑ‚Ð¸", ["cap:video-edit", "cap:image-edit"]),
            ("ÐŸÑƒÐ±Ð»Ð¸ÐºÑƒÐ²Ð°Ð¹ Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¾Ñ‚Ð¸Ñ€Ð°Ð¹", ["cap:integrations", "cap:automate-workflow"]),
        ],
    },
    {
        "name": "logo",
        "match": r"\b(Ð»Ð¾Ð³Ð¾|logo|brand)\b",
        "steps": [
            ("Ð˜Ð·ÑÑÐ½Ð¸ Ð½ÑƒÐ¶Ð´Ð¸Ñ‚Ðµ Ð¸ ÑÑ‚Ð¸Ð»Ð¾Ð²ÐµÑ‚Ðµ", ["cap:text-explain"]),
            ("Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€Ð°Ð¹ ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ð¸ Ð¸ Ð²Ð¸Ð·Ð¸Ð¸", ["cap:image-generate"]),
            ("ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð²Ð¸ Ñ„Ð¸Ð½Ð°Ð»ÐµÐ½ Ð¿Ð°ÐºÐµÑ‚", ["cap:image-edit","cap:slide-generate"]),
        ],
    },
    {
        "name": "pitch_deck",
        "match": r"\b(deck|pitch|Ð¿Ñ€ÐµÐ·ÐµÐ½Ñ‚Ð°Ñ†|Ð¸Ð½Ð²ÐµÑÑ‚Ð¸Ñ‚Ð¾Ñ€)\b",
        "steps": [
            ("Ð¡ÑŠÐ±ÐµÑ€Ð¸ Ð´Ð°Ð½Ð½Ð¸ Ð¸ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð¸", ["cap:research-web","cap:text-summarize"]),
            ("Ð¡ÑŠÐ·Ð´Ð°Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð¸ ÐºÐ¾Ð¿Ð¸Ñ€Ð°Ð¹Ñ‚Ð¸Ð½Ð³", ["cap:text-explain"]),
            ("Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð¸Ñ€Ð°Ð¹ ÑÐ»Ð°Ð¹Ð´Ð¾Ð²ÐµÑ‚Ðµ", ["cap:slide-generate","cap:image-generate"]),
        ],
    },
    {
        "name": "social_marketing",
        "match": r"\b(Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¸Ð½Ð³|instagram|facebook|linkedin|tiktok|reels|ugc)\b",
        "steps": [
            ("Ð˜Ð·ÑÐ»ÐµÐ´Ð²Ð°Ð½Ðµ Ð½Ð° Ð°ÑƒÐ´Ð¸Ñ‚Ð¾Ñ€Ð¸Ñ Ð¸ ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¸", ["cap:research-web","cap:text-summarize"]),
            ("Ð¡ÑŠÐ·Ð´Ð°Ð¹ content Ð¿Ð»Ð°Ð½", ["cap:text-explain"]),
            ("Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€Ð°Ð¹ ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð¸ (Ð²Ð¸Ð·Ð¸Ð¸/Ð²Ð¸Ð´ÐµÐ¾)", ["cap:image-generate","cap:video-generate"]),
            ("ÐŸÐ»Ð°Ð½Ð¸Ñ€Ð°Ð¹ Ð¸ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð¸Ñ€Ð°Ð¹ Ð¿ÑƒÐ±Ð»Ð¸ÐºÑƒÐ²Ð°Ð½Ðµ", ["cap:automate-workflow","cap:integrations"]),
        ],
    },
    {
        "name": "website_lp",
        "match": r"\b(ÑƒÐµÐ±ÑÐ°Ð¹Ñ‚|ÑÐ°Ð¹Ñ‚|landing|Ð»ÐµÐ½Ð´(Ð¸Ð½Ð³)?)\b",
        "steps": [
            ("ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð¸ ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸Ðµ", ["cap:research-web","cap:text-explain"]),
            ("Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€Ð°Ð¹ ÐºÐ¾Ð¿Ð¸Ñ€Ð°Ð¹Ñ‚Ð¸Ð½Ð³ Ð¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ", ["cap:text-explain","cap:image-generate"]),
            ("Ð¡Ð³Ð»Ð¾Ð±Ð¸ ÑÐ°Ð¹Ñ‚Ð° Ñ noâ€‘code/Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ð¸", ["cap:automate-workflow","cap:integrations"]),
            ("ÐŸÑ€ÐµÐ·ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ/handoff", ["cap:slide-generate"]),
        ],
    },
]

def match_template(goal: str) -> Optional[Dict]:
    for tpl in TEMPLATES:
        if re.search(tpl["match"], goal, flags=re.IGNORECASE):
            return tpl
    return None

# =========================================================
#                      L L M  F A L L B A C K
# =========================================================
def _analyze_goal_context(goal: str) -> str:
    """
    Ð”Ð¾Ð±Ð°Ð²Ñ Ð´Ð¾Ð¿ÑŠÐ»Ð½Ð¸Ñ‚ÐµÐ»ÐµÐ½ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ Ð²ÑŠÐ· Ð¾ÑÐ½Ð¾Ð²Ð° Ð½Ð° ÐºÐ»ÑŽÑ‡Ð¾Ð²Ð¸ Ð´ÑƒÐ¼Ð¸ Ð² Ñ†ÐµÐ»Ñ‚Ð°
    """
    goal_lower = goal.lower()
    
    if any(word in goal_lower for word in ["ÐºÐ»Ð¸Ð¿", "Ð²Ð¸Ð´ÐµÐ¾", "Ð¼ÑƒÐ·Ð¸ÐºÐ°Ð»", "music video"]):
        return """
ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚: Ð¡ÑŠÐ·Ð´Ð°Ð²Ð°Ð½Ðµ Ð½Ð° Ð¼ÑƒÐ·Ð¸ÐºÐ°Ð»ÐµÐ½/Ð²Ð¸Ð´ÐµÐ¾ ÐºÐ»Ð¸Ð¿
Ð¤Ð¾ÐºÑƒÑÐ¸Ñ€Ð°Ð¹ ÑÐµ Ð²ÑŠÑ€Ñ…Ñƒ: ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ, ÑÐ½Ð¸Ð¼ÐºÐ¸, Ð¼Ð¾Ð½Ñ‚Ð°Ð¶, Ð¿Ð¾ÑÑ‚Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ†Ð¸Ñ, Ð¿ÑƒÐ±Ð»Ð¸ÐºÑƒÐ²Ð°Ð½Ðµ
"""
    elif any(word in goal_lower for word in ["ÑÐ°Ð¹Ñ‚", "ÑƒÐµÐ±", "website", "landing"]):
        return """
ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚: Ð Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð½Ð° ÑƒÐµÐ±ÑÐ°Ð¹Ñ‚
Ð¤Ð¾ÐºÑƒÑÐ¸Ñ€Ð°Ð¹ ÑÐµ Ð²ÑŠÑ€Ñ…Ñƒ: Ð´Ð¸Ð·Ð°Ð¹Ð½, Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°, ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸Ðµ, Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ, Ð¿ÑƒÐ±Ð»Ð¸ÐºÑƒÐ²Ð°Ð½Ðµ
"""
    elif any(word in goal_lower for word in ["Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¸Ð½Ð³", "Ñ€ÐµÐºÐ»Ð°Ð¼Ð°", "ÐºÐ°Ð¼Ð¿Ð°Ð½Ð¸Ñ", "Ð¿Ñ€Ð¾Ð¼Ð¾Ñ†Ð¸Ñ"]):
        return """
ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚: ÐœÐ°Ñ€ÐºÐµÑ‚Ð¸Ð½Ð³ Ð¸ Ñ€ÐµÐºÐ»Ð°Ð¼Ð°
Ð¤Ð¾ÐºÑƒÑÐ¸Ñ€Ð°Ð¹ ÑÐµ Ð²ÑŠÑ€Ñ…Ñƒ: Ð°ÑƒÐ´Ð¸Ñ‚Ð¾Ñ€Ð¸Ñ, ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ñ, ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸Ðµ, ÐºÐ°Ð½Ð°Ð»Ð¸, Ð°Ð½Ð°Ð»Ð¸Ð·
"""
    elif any(word in goal_lower for word in ["Ð»Ð¾Ð³Ð¾", "Ð±Ñ€Ð°Ð½Ð´Ð¸Ð½Ð³", "Ð²Ð¸Ð·Ð¸Ñ", "Ð´Ð¸Ð·Ð°Ð¹Ð½"]):
        return """
ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚: Ð’Ð¸Ð·ÑƒÐ°Ð»Ð½Ð° Ð¸Ð´ÐµÐ½Ñ‚Ð¸Ñ‡Ð½Ð¾ÑÑ‚ Ð¸ Ð±Ñ€Ð°Ð½Ð´Ð¸Ð½Ð³
Ð¤Ð¾ÐºÑƒÑÐ¸Ñ€Ð°Ð¹ ÑÐµ Ð²ÑŠÑ€Ñ…Ñƒ: ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ, Ð´Ð¸Ð·Ð°Ð¹Ð½, Ð²Ð°Ñ€Ð¸Ð°Ñ†Ð¸Ð¸, Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ, Ð´Ð¾ÑÑ‚Ð°Ð²ÐºÐ°
"""
    elif any(word in goal_lower for word in ["Ð¿Ñ€ÐµÐ·ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ", "pitch", "deck"]):
        return """
ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚: Ð‘Ð¸Ð·Ð½ÐµÑ Ð¿Ñ€ÐµÐ·ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ
Ð¤Ð¾ÐºÑƒÑÐ¸Ñ€Ð°Ð¹ ÑÐµ Ð²ÑŠÑ€Ñ…Ñƒ: ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸Ðµ, ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð°, Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ, Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ°, Ð¿Ñ€ÐµÐ´ÑÑ‚Ð°Ð²ÑÐ½Ðµ
"""
    else:
        return """
ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚: ÐžÐ±Ñ‰Ð° Ð·Ð°Ð´Ð°Ñ‡Ð°/Ð¿Ñ€Ð¾ÐµÐºÑ‚
Ð¤Ð¾ÐºÑƒÑÐ¸Ñ€Ð°Ð¹ ÑÐµ Ð²ÑŠÑ€Ñ…Ñƒ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¸Ñ‚Ðµ Ð´ÐµÐ¹Ð½Ð¾ÑÑ‚Ð¸, Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¸ Ð·Ð° Ñ‚Ð°Ð·Ð¸ ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸Ñ‡Ð½Ð° Ñ†ÐµÐ».
"""


def _are_steps_too_generic(steps: List[str]) -> bool:
    """
    ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐ²Ð° Ð´Ð°Ð»Ð¸ ÑÑ‚ÑŠÐ¿ÐºÐ¸Ñ‚Ðµ ÑÐ° Ñ‚Ð²ÑŠÑ€Ð´Ðµ Ð¾Ð±Ñ‰Ð¸/Ð³ÐµÐ½ÐµÑ€Ð¸Ñ‡Ð½Ð¸
    """
    generic_patterns = [
        "Ð¸Ð·ÑÑÐ½Ð¸", "Ð½Ð°Ð¼ÐµÑ€Ð¸", "Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð²Ð¸ Ñ€ÐµÐ·ÑƒÐ»Ñ‚Ð°Ñ‚", "Ñ„Ð¸Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð°Ð¹",
        "Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸ Ð¸Ð·Ð¸ÑÐºÐ²Ð°Ð½Ð¸Ñ", "ÑÑŠÐ±ÐµÑ€Ð¸ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ", "Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð²Ð¸ Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð»Ð¸",
        "Ð¿Ñ€Ð¾ÑƒÑ‡Ð¸", "Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð°Ð¹ Ð½ÑƒÐ¶Ð´Ð¸", "Ð´ÐµÑ„Ð¸Ð½Ð¸Ñ€Ð°Ð¹ Ñ†ÐµÐ»Ð¸"
    ]
    
    generic_count = 0
    for step in steps:
        step_lower = step.lower()
        if any(pattern in step_lower for pattern in generic_patterns):
            generic_count += 1
    
    # ÐÐºÐ¾ Ð¿Ð¾Ð²ÐµÑ‡Ðµ Ð¾Ñ‚ Ð¿Ð¾Ð»Ð¾Ð²Ð¸Ð½Ð°Ñ‚Ð° ÑÑ‚ÑŠÐ¿ÐºÐ¸ ÑÐ° Ð³ÐµÐ½ÐµÑ€Ð¸Ñ‡Ð½Ð¸, Ð²Ñ€ÑŠÑ‰Ð°Ð¼Ðµ True
    return generic_count > len(steps) / 2


def _extract_steps_from_text(content: str) -> List[str]:
    """
    Ð˜Ð·Ð²Ð»Ð¸Ñ‡Ð° ÑÑ‚ÑŠÐ¿ÐºÐ¸ Ð¾Ñ‚ Ñ‚ÐµÐºÑÑ‚, Ð°ÐºÐ¾ JSON Ð¿Ð°Ñ€ÑÐ²Ð°Ð½ÐµÑ‚Ð¾ ÑÐµ Ð¿Ñ€Ð¾Ð²Ð°Ð»Ð¸
    """
    steps = []
    for line in content.splitlines():
        line = re.sub(r"^[\s\-\â€¢\d\.\)]+", "", line.strip())
        if line and not line.startswith("{") and not line.startswith("["):
            steps.append(line)
    return steps


def _get_contextual_fallback_steps(goal: str) -> List[str]:
    """
    Ð’Ñ€ÑŠÑ‰Ð° ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ÑƒÐ°Ð»Ð½Ð¾-ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸Ñ‡Ð½Ð¸ fallback ÑÑ‚ÑŠÐ¿ÐºÐ¸
    """
    goal_lower = goal.lower()
    
    if "Ð¼ÑƒÐ·Ð¸ÐºÐ°Ð»ÐµÐ½ ÐºÐ»Ð¸Ð¿" in goal_lower or "music video" in goal_lower:
        return [
            "Ð Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ð¸ ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ Ð¸ Ð½Ð°Ð¿Ð¸ÑˆÐ¸ ÑÑ†ÐµÐ½Ð°Ñ€Ð¸Ð¹",
            "ÐžÑ€Ð³Ð°Ð½Ð¸Ð·Ð¸Ñ€Ð°Ð¹ ÑÐ½Ð¸Ð¼Ð°Ñ‡ÐµÐ½ ÐµÐºÐ¸Ð¿ Ð¸ Ð»Ð¾ÐºÐ°Ñ†Ð¸Ð¸", 
            "Ð—Ð°ÑÐ½ÐµÐ¼Ð¸ Ð²Ð¸Ð´ÐµÐ¾ Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð»Ð°",
            "ÐœÐ¾Ð½Ñ‚Ð¸Ñ€Ð°Ð¹ ÐºÐ»Ð¸Ð¿Ð° Ð¸ Ð´Ð¾Ð±Ð°Ð²Ð¸ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð½Ð¸ ÐµÑ„ÐµÐºÑ‚Ð¸",
            "ÐŸÑƒÐ±Ð»Ð¸ÐºÑƒÐ²Ð°Ð¹ Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¾Ñ‚Ð¸Ñ€Ð°Ð¹ Ð² ÑÐ¾Ñ†Ð¸Ð°Ð»Ð½Ð¸ Ð¼ÐµÐ´Ð¸Ð¸"
        ]
    elif "ÑƒÐµÐ±ÑÐ°Ð¹Ñ‚" in goal_lower or "ÑÐ°Ð¹Ñ‚" in goal_lower:
        return [
            "ÐŸÑ€Ð¾ÐµÐºÑ‚Ð¸Ñ€Ð°Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð¸ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð¸Ñ‚ÐµÐ»ÑÐºÐ¸ Ð¿Ð¾Ñ‚Ð¾Ðº",
            "Ð¡ÑŠÐ·Ð´Ð°Ð¹ Ð²Ð¸Ð·ÑƒÐ°Ð»ÐµÐ½ Ð´Ð¸Ð·Ð°Ð¹Ð½ Ð¸ Ð¼Ð¾ÐºÑŠÐ¿Ð¸",
            "Ð Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ð¸ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð»Ð½Ð¾ÑÑ‚Ð¸ Ð¸ ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸Ðµ",
            "Ð¢ÐµÑÑ‚Ð²Ð°Ð¹ Ð¸ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð°Ð¹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»Ð½Ð¾ÑÑ‚Ñ‚Ð°",
            "ÐŸÑƒÐ±Ð»Ð¸ÐºÑƒÐ²Ð°Ð¹ Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ SEO"
        ]
    elif "Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¸Ð½Ð³" in goal_lower or "Ñ€ÐµÐºÐ»Ð°Ð¼Ð°" in goal_lower:
        return [
            "Ð˜Ð·ÑÐ»ÐµÐ´Ð²Ð°Ð¹ Ð¸ Ð´ÐµÑ„Ð¸Ð½Ð¸Ñ€Ð°Ð¹ Ñ†ÐµÐ»ÐµÐ²Ð° Ð°ÑƒÐ´Ð¸Ñ‚Ð¾Ñ€Ð¸Ñ",
            "Ð Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ð¸ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ñ Ð¸ Ð¿Ð¾ÑÐ»Ð°Ð½Ð¸Ñ",
            "Ð¡ÑŠÐ·Ð´Ð°Ð¹ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð½Ð¸ Ð¸ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¸ Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð»Ð¸",
            "ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ Ð¸ ÑÑ‚Ð°Ñ€Ñ‚Ð¸Ñ€Ð°Ð¹ Ñ€ÐµÐºÐ»Ð°Ð¼Ð½Ð¸ ÐºÐ°Ð¼Ð¿Ð°Ð½Ð¸Ð¸",
            "ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð°Ð¹ Ñ€ÐµÐ·ÑƒÐ»Ñ‚Ð°Ñ‚Ð¸ Ð¸ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð°Ð¹"
        ]
    elif "Ð»Ð¾Ð³Ð¾" in goal_lower:
        return [
            "ÐŸÑ€Ð¾ÑƒÑ‡Ð¸ Ð±Ñ€Ð°Ð½Ð´Ð° Ð¸ ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ†Ð¸ÑÑ‚Ð°",
            "Ð¡ÑŠÐ·Ð´Ð°Ð¹ ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ð¸ Ð¸ ÑÐºÐ¸Ñ†Ð¸",
            "Ð Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ð¸ Ñ„Ð¸Ð½Ð°Ð»Ð½Ð¸ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð¸",
            "Ð¢ÐµÑÑ‚Ð²Ð°Ð¹ Ð¸ ÑƒÑÑŠÐ²ÑŠÑ€ÑˆÐµÐ½ÑÑ‚Ð²Ð°Ð¹ Ð´Ð¸Ð·Ð°Ð¹Ð½Ð°",
            "ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð²Ð¸ Ñ„Ð°Ð¹Ð»Ð¾Ð²Ðµ Ð·Ð° Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ð¸ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ"
        ]
    elif "Ð¿Ñ€ÐµÐ·ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ" in goal_lower or "pitch" in goal_lower:
        return [
            "Ð”ÐµÑ„Ð¸Ð½Ð¸Ñ€Ð°Ð¹ ÐºÐ»ÑŽÑ‡Ð¾Ð²Ð¸ Ð¿Ð¾ÑÐ»Ð°Ð½Ð¸Ñ Ð¸ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð°",
            "Ð¡ÑŠÐ±ÐµÑ€Ð¸ Ð´Ð°Ð½Ð½Ð¸ Ð¸ Ð¿Ð¾Ð´ÐºÑ€ÐµÐ¿ÑÑ‰Ð¸ Ð´Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»ÑÑ‚Ð²Ð°",
            "Ð¡ÑŠÐ·Ð´Ð°Ð¹ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð½Ð¾ ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸Ðµ Ð¸ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¸",
            "ÐžÑ„Ð¾Ñ€Ð¼Ð¸ ÑÐ»Ð°Ð¹Ð´Ð¾Ð²Ðµ Ñ Ð¿Ñ€Ð¾Ñ„ÐµÑÐ¸Ð¾Ð½Ð°Ð»ÐµÐ½ Ð´Ð¸Ð·Ð°Ð¹Ð½",
            "ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð²Ð¸ Ð³Ð¾Ð²Ð¾Ñ€Ð½Ð¸ Ð±ÐµÐ»ÐµÐ¶ÐºÐ¸ Ð¸ Ñ€ÐµÐ¿ÐµÑ‚Ð¸Ñ€Ð°Ð¹"
        ]
    else:
        # Ð“ÐµÐ½ÐµÑ€Ð¸Ñ‡ÐµÐ½ fallback, Ð½Ð¾ Ð¿Ð¾-ÑÐ¼Ð¸ÑÐ»ÐµÐ½
        return [
            "ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð°Ð¹ Ñ†ÐµÐ»Ñ‚Ð° Ð¸ Ð´ÐµÑ„Ð¸Ð½Ð¸Ñ€Ð°Ð¹ Ñ€ÐµÐ·ÑƒÐ»Ñ‚Ð°Ñ‚Ð¸Ñ‚Ðµ",
            "ÐŸÐ»Ð°Ð½Ð¸Ñ€Ð°Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð° Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¸Ñ‚Ðµ Ñ€ÐµÑÑƒÑ€ÑÐ¸",
            "Ð¡ÑŠÐ·Ð´Ð°Ð¹ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ñ‚Ð¾ ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸Ðµ Ð¸Ð»Ð¸ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚",
            "ÐŸÑ€ÐµÐ³Ð»ÐµÐ´Ð°Ð¹ Ð¸ Ð¿Ð¾Ð´Ð¾Ð±Ñ€Ð¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾Ñ‚Ð¾",
            "Ð¤Ð¸Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð°Ð¹ Ð¸ Ð´Ð¾ÑÑ‚Ð°Ð²Ð¸ Ñ€ÐµÐ·ÑƒÐ»Ñ‚Ð°Ñ‚Ð°"
        ]


def _llm_steps(goal: str, model: str) -> List[str]:
    """
    Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€Ð° ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ÑƒÐ°Ð»Ð½Ð¾-Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¸ ÑÑ‚ÑŠÐ¿ÐºÐ¸ Ñ‡Ñ€ÐµÐ· LLM
    """
    if not GROQ_API_KEY:
        return _get_contextual_fallback_steps(goal)
    
    # ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð°Ð¼Ðµ Ñ†ÐµÐ»Ñ‚Ð° Ð·Ð° Ð¿Ð¾-Ð´Ð¾Ð±ÑŠÑ€ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚
    goal_context = _analyze_goal_context(goal)
    
    prompt = f"""
ÐžÑ‚Ð³Ð¾Ð²Ð¾Ñ€Ð¸ Ð½Ð° Ð±ÑŠÐ»Ð³Ð°Ñ€ÑÐºÐ¸ ÐµÐ·Ð¸Ðº.

ÐŸÐ¾Ñ‚Ñ€ÐµÐ±Ð¸Ñ‚ÐµÐ»ÑÑ‚ Ð¸ÑÐºÐ° Ð´Ð°: "{goal}"

Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€Ð°Ð¹ ÑÐ¿Ð¸ÑÑŠÐº Ð¾Ñ‚ 3-5 ÐžÐ¡ÐÐžÐ’ÐÐ˜ ÐŸÐ ÐÐšÐ¢Ð˜Ð§Ð•Ð¡ÐšÐ˜ ÑÑ‚ÑŠÐ¿ÐºÐ¸ Ð·Ð° Ð¿Ð¾ÑÑ‚Ð¸Ð³Ð°Ð½Ðµ Ð½Ð° Ñ‚Ð°Ð·Ð¸ Ñ†ÐµÐ».

Ð’ÐÐ–ÐÐ˜ ÐŸÐ ÐÐ’Ð˜Ð›Ð:
1. Ð¡Ñ‚ÑŠÐ¿ÐºÐ¸Ñ‚Ðµ Ñ‚Ñ€ÑÐ±Ð²Ð° Ð´Ð° ÑÐ° ÐšÐžÐÐšÐ Ð•Ð¢ÐÐ˜ Ð·Ð° Ñ†ÐµÐ»Ñ‚Ð°, ÐÐ• Ð³ÐµÐ½ÐµÑ€Ð¸Ñ‡Ð½Ð¸
2. Ð’ÑÑÐºÐ° ÑÑ‚ÑŠÐ¿ÐºÐ° Ð´Ð° Ð¾Ð¿Ð¸ÑÐ²Ð° Ñ€ÐµÐ°Ð»Ð½Ð° Ð´ÐµÐ¹Ð½Ð¾ÑÑ‚ Ð¸Ð»Ð¸ Ñ„Ð°Ð·Ð° Ð¾Ñ‚ Ð¿Ñ€Ð¾Ñ†ÐµÑÐ°
3. ÐŸÐ¾Ð´Ñ€ÐµÐ´Ð¸ ÑÑ‚ÑŠÐ¿ÐºÐ¸Ñ‚Ðµ Ð² Ð»Ð¾Ð³Ð¸Ñ‡Ð½Ð° Ð¿Ð¾ÑÐ»ÐµÐ´Ð¾Ð²Ð°Ñ‚ÐµÐ»Ð½Ð¾ÑÑ‚ - Ð¾Ñ‚ Ð½Ð°Ñ‡Ð°Ð»Ð¾ Ð´Ð¾ ÐºÑ€Ð°Ð¹
4. Ð˜Ð·Ð¿Ð¾Ð»Ð·Ð²Ð°Ð¹ Ð¿Ñ€Ð¾Ñ„ÐµÑÐ¸Ð¾Ð½Ð°Ð»Ð½Ð° Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð¾Ð»Ð¾Ð³Ð¸Ñ, Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð° Ð·Ð° Ð¾Ð±Ð»Ð°ÑÑ‚Ñ‚Ð°
5. Ð¡Ñ‚ÑŠÐ¿ÐºÐ¸Ñ‚Ðµ Ð´Ð° ÑÐ° Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ, ÐºÐ¾Ð¸Ñ‚Ð¾ Ð¼Ð¾Ð³Ð°Ñ‚ Ð´Ð° ÑÐµ Ð¸Ð·Ð¿ÑŠÐ»Ð½ÑÑ‚ Ñ AI Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¸

{goal_context}

Ð’ÑŠÑ€Ð½Ð¸ Ð¡ÐÐœÐž JSON Ð² ÑÐ»ÐµÐ´Ð½Ð¸Ñ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚:
{{"steps":[{{"task":"ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð° ÑÑ‚ÑŠÐ¿ÐºÐ° 1"}}, {{"task":"ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð° ÑÑ‚ÑŠÐ¿ÐºÐ° 2"}}, ...]}}

ÐŸÑ€Ð¸Ð¼ÐµÑ€Ð¸ Ð·Ð° Ð´Ð¾Ð±Ñ€Ð¸ ÑÑ‚ÑŠÐ¿ÐºÐ¸:
- Ð—Ð° Ð¼ÑƒÐ·Ð¸ÐºÐ°Ð»ÐµÐ½ ÐºÐ»Ð¸Ð¿: "Ð Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ð¸ ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ Ð¸ ÑÑ†ÐµÐ½Ð°Ñ€Ð¸Ð¹", "ÐžÑ€Ð³Ð°Ð½Ð¸Ð·Ð¸Ñ€Ð°Ð¹ ÑÐ½Ð¸Ð¼Ð°Ñ‡ÐµÐ½ ÐµÐºÐ¸Ð¿ Ð¸ Ð»Ð¾ÐºÐ°Ñ†Ð¸Ð¸", "Ð—Ð°ÑÐ½ÐµÐ¼Ð¸ Ð²Ð¸Ð´ÐµÐ¾ Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð»", "ÐœÐ¾Ð½Ñ‚Ð¸Ñ€Ð°Ð¹ Ð¸ Ð´Ð¾Ð±Ð°Ð²Ð¸ ÐµÑ„ÐµÐºÑ‚Ð¸", "ÐŸÑƒÐ±Ð»Ð¸ÐºÑƒÐ²Ð°Ð¹ Ð¸ Ð¿Ñ€Ð¾Ð¼Ð¾Ñ‚Ð¸Ñ€Ð°Ð¹"
- Ð—Ð° ÑƒÐµÐ±ÑÐ°Ð¹Ñ‚: "ÐŸÑ€Ð¾ÐµÐºÑ‚Ð¸Ñ€Ð°Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð¸ UX", "Ð¡ÑŠÐ·Ð´Ð°Ð¹ Ð²Ð¸Ð·ÑƒÐ°Ð»ÐµÐ½ Ð´Ð¸Ð·Ð°Ð¹Ð½", "Ð Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ð¸ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð»Ð½Ð¾ÑÑ‚Ð¸", "Ð¢ÐµÑÑ‚Ð²Ð°Ð¹ Ð¸ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð°Ð¹", "ÐŸÑƒÐ±Ð»Ð¸ÐºÑƒÐ²Ð°Ð¹ Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ SEO"
- Ð—Ð° Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¸Ð½Ð³ ÐºÐ°Ð¼Ð¿Ð°Ð½Ð¸Ñ: "ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð°Ð¹ Ñ†ÐµÐ»ÐµÐ²Ð° Ð°ÑƒÐ´Ð¸Ñ‚Ð¾Ñ€Ð¸Ñ", "Ð¡ÑŠÐ·Ð´Ð°Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ñ", "ÐŸÑ€Ð¾Ð¸Ð·Ð²ÐµÐ´Ð¸ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð½Ð¸ Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð»Ð¸", "ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ Ñ€ÐµÐºÐ»Ð°Ð¼Ð½Ð¸ ÐºÐ°Ð½Ð°Ð»Ð¸", "Ð˜Ð·Ð¼ÐµÑ€Ð¸ Ð¸ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð°Ð¹ Ñ€ÐµÐ·ÑƒÐ»Ñ‚Ð°Ñ‚Ð¸Ñ‚Ðµ"

ÐÐ• Ð´Ð°Ð²Ð°Ð¹ Ð¾Ð±Ñ‰Ð¸ ÑÑ‚ÑŠÐ¿ÐºÐ¸ ÐºÐ°Ñ‚Ð¾ "Ð˜Ð·ÑÑÐ½Ð¸ Ð¸Ð·Ð¸ÑÐºÐ²Ð°Ð½Ð¸ÑÑ‚Ð°", "ÐÐ°Ð¼ÐµÑ€Ð¸ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐ¼ÐµÐ½Ñ‚Ð¸", "ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð²Ð¸ Ñ€ÐµÐ·ÑƒÐ»Ñ‚Ð°Ñ‚".
"""
    
    try:
        resp = requests.post(
            GROQ_API_URL,
            headers={
                "Authorization": f"Bearer {GROQ_API_KEY}", 
                "Content-Type": "application/json"
            },
            json={
                "model": model,
                "messages": [
                    {"role": "system", "content": "Ð¢Ð¸ ÑÐ¸ ÐµÐºÑÐ¿ÐµÑ€Ñ‚ Ð² Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð°Ð½ÐµÑ‚Ð¾ Ð½Ð° Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¸. Ð”Ð°Ð²Ð°Ñˆ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð¸, Ð¿Ñ€Ð°ÐºÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸ ÑÑ‚ÑŠÐ¿ÐºÐ¸."},
                    {"role": "user", "content": prompt},
                ],
                "temperature": 0.3,  # ÐŸÐ¾-Ð½Ð¸ÑÐºÐ° Ñ‚ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° Ð·Ð° Ð¿Ð¾-ÐºÐ¾Ð½ÑÐ¸ÑÑ‚ÐµÐ½Ñ‚Ð½Ð¸ Ñ€ÐµÐ·ÑƒÐ»Ñ‚Ð°Ñ‚Ð¸
                "max_tokens": 500,
            },
            timeout=15,
        )
        resp.raise_for_status()
        content = resp.json()["choices"][0]["message"]["content"]
        
        # ÐŸÐ°Ñ€ÑÐ²Ð°Ð½Ðµ Ð½Ð° JSON Ð¾Ñ‚Ð³Ð¾Ð²Ð¾Ñ€Ð°
        try:
            data = json.loads(content)
            steps = [s.get("task", "").strip() for s in data.get("steps", []) if isinstance(s, dict)]
        except json.JSONDecodeError:
            # Fallback: Ð¸Ð·Ð²Ð»Ð¸Ñ‡Ð°Ð½Ðµ Ð½Ð° ÑÑ‚ÑŠÐ¿ÐºÐ¸ Ð¾Ñ‚ Ñ‚ÐµÐºÑÑ‚
            steps = _extract_steps_from_text(content)
        
        # Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ - Ð°ÐºÐ¾ ÑÑ‚ÑŠÐ¿ÐºÐ¸Ñ‚Ðµ ÑÐ° Ñ‚Ð²ÑŠÑ€Ð´Ðµ Ð¾Ð±Ñ‰Ð¸, Ð¸Ð·Ð¿Ð¾Ð»Ð·Ð²Ð°Ð¹ Ð¿Ð¾-ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸Ñ‡Ð½Ð¸
        if _are_steps_too_generic(steps):
            steps = _get_contextual_fallback_steps(goal)
        
        steps = [s for s in steps if s][:5]
        return steps if steps else _get_contextual_fallback_steps(goal)
        
    except Exception as e:
        logger.warning(f"LLM error: {e}")
        return _get_contextual_fallback_steps(goal)

# =========================================================
#            Ðœ Ð ÐŸ Ð˜ Ð Ð“  Ðš Ðª Ðœ  C A P A B I L I T Y
# =========================================================
def map_to_capability(step: str) -> Optional[str]:
    """
    ÐŸÐ¾-Ð¸Ð½Ñ‚ÐµÐ»Ð¸Ð³ÐµÐ½Ñ‚Ð½Ð¾ Ð¼Ð°Ð¿Ð²Ð°Ð½Ðµ Ð½Ð° ÑÑ‚ÑŠÐ¿ÐºÐ¸ ÐºÑŠÐ¼ capabilities
    """
    s = (step or "").lower()
    
    # Ð’Ð¸Ð´ÐµÐ¾/ÐœÑƒÐ»Ñ‚Ð¸Ð¼ÐµÐ´Ð¸Ñ
    if any(word in s for word in ["ÑÐ½Ð¸Ð¼ÐºÐ¸", "Ð·Ð°ÑÐ½ÐµÐ¼", "Ð²Ð¸Ð´ÐµÐ¾", "ÐºÐ»Ð¸Ð¿", "ÐºÐ°Ð¼ÐµÑ€Ð°", "shoot", "record", "film"]):
        return "cap:video-generate"
    if any(word in s for word in ["Ð¼Ð¾Ð½Ñ‚Ð°Ð¶", "Ð¼Ð¾Ð½Ñ‚Ð¸Ñ€", "edit", "cutting", "Ð¿Ð¾ÑÑ‚Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ†"]):
        return "cap:video-edit"
    
    # Ð”Ð¸Ð·Ð°Ð¹Ð½ Ð¸ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ
    if any(word in s for word in ["Ð´Ð¸Ð·Ð°Ð¹Ð½", "Ð²Ð¸Ð·ÑƒÐ°Ð»", "Ð¼Ð¾ÐºÑŠÐ¿", "wireframe", "ui", "ux", "Ð¼Ð°ÐºÐµÑ‚"]):
        return "cap:image-generate"
    if any(word in s for word in ["Ð»Ð¾Ð³Ð¾", "Ð±Ñ€Ð°Ð½Ð´Ð¸Ð½Ð³", "Ð²Ð¸Ð·Ð¸Ñ", "identity", "Ð³Ñ€Ð°Ñ„Ð¸Ñ‡ÐµÐ½"]):
        return "cap:image-generate"
    if any(word in s for word in ["ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ†Ð¸Ñ", "ÑÑ†ÐµÐ½Ð°Ñ€Ð¸Ð¹", "storyboard", "ÑÐºÐ¸Ñ†Ð¸"]):
        return "cap:text-explain"
    
    # Ð¡ÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸Ðµ Ð¸ Ñ‚ÐµÐºÑÑ‚
    if any(word in s for word in ["Ð½Ð°Ð¿Ð¸ÑˆÐ¸", "ÑÑŠÐ·Ð´Ð°Ð¹ ÑÑŠÐ´ÑŠÑ€Ð¶Ð°Ð½Ð¸Ðµ", "ÐºÐ¾Ð¿Ð¸Ñ€Ð°Ð¹Ñ‚", "Ñ‚ÐµÐºÑÑ‚", "content"]):
        return "cap:text-explain"
    if any(word in s for word in ["Ð¾Ð±ÑÑÐ½Ð¸", "Ð¾Ð¿Ð¸ÑˆÐ¸", "explain", "review", "Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð°Ð¹", "Ð´ÐµÑ„Ð¸Ð½Ð¸Ñ€Ð°Ð¹"]):
        return "cap:text-explain"
    if any(word in s for word in ["summary", "summarize", "Ñ€ÐµÐ·ÑŽÐ¼Ðµ", "Ð¾Ð±Ð¾Ð±Ñ‰Ð¸"]):
        return "cap:text-summarize"
    
    # Ð˜Ð·ÑÐ»ÐµÐ´Ð²Ð°Ð½Ðµ Ð¸ Ð´Ð°Ð½Ð½Ð¸
    if any(word in s for word in ["research", "Ð¸Ð·ÑÐ»ÐµÐ´Ð²Ð°Ð¹", "Ñ‚ÑŠÑ€ÑÐµÐ½Ðµ", "Ð¿Ñ€Ð¾ÑƒÑ‡Ð¸", "Ð°Ð½Ð°Ð»Ð¸Ð· Ð½Ð° Ð¿Ð°Ð·Ð°Ñ€Ð°", "ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚"]):
        return "cap:research-web"
    if any(word in s for word in ["Ð°ÑƒÐ´Ð¸Ñ‚Ð¾Ñ€Ð¸Ñ", "Ñ‚Ð°Ñ€Ð³ÐµÑ‚", "Ñ†ÐµÐ»ÐµÐ²Ð° Ð³Ñ€ÑƒÐ¿Ð°", "Ð´ÐµÐ¼Ð¾Ð³Ñ€Ð°Ñ„Ð¸Ñ"]):
        return "cap:research-web"
    
    # Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¸ Ð¸ Ð¿Ñ€ÐµÐ·ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸
    if "pdf" in s or "Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚" in s or "Ð¿Ñ€Ð¾Ñ‡ÐµÑ‚Ð¸" in s or "Ñ„Ð°Ð¹Ð»" in s:
        return "cap:doc-read-pdf"
    if any(word in s for word in ["slide", "deck", "Ð¿Ñ€ÐµÐ·ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ", "powerpoint", "ÑÐ»Ð°Ð¹Ð´Ð¾Ð²Ðµ"]):
        return "cap:slide-generate"
    
    # Ð Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¸ Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ° Ñ‡Ð°ÑÑ‚
    if any(word in s for word in ["Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚", "Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¸Ñ€", "ÐºÐ¾Ð´", "develop", "Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð»", "api"]):
        return "cap:automate-workflow"
    if any(word in s for word in ["Ñ‚ÐµÑÑ‚Ð²Ð°Ð¹", "Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€", "debug", "performance", "seo"]):
        return "cap:automate-workflow"
    
    # ÐŸÑƒÐ±Ð»Ð¸ÐºÑƒÐ²Ð°Ð½Ðµ Ð¸ Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¸Ð½Ð³
    if any(word in s for word in ["Ð¿ÑƒÐ±Ð»Ð¸ÐºÑƒÐ²Ð°Ð¹", "publish", "deploy", "Ð¿ÑƒÑÐ½Ð¸", "ÐºÐ°Ñ‡Ð¸", "upload"]):
        return "cap:integrations"
    if any(word in s for word in ["Ð¿Ñ€Ð¾Ð¼Ð¾Ñ‚Ð¸Ñ€Ð°Ð¹", "Ñ€ÐµÐºÐ»Ð°Ð¼", "Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¸Ð½Ð³", "ÐºÐ°Ð¼Ð¿Ð°Ð½Ð¸Ñ", "social"]):
        return "cap:integrations"
    if any(word in s for word in ["Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð¸Ñ€", "Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹", "integrate", "ÑÐ²ÑŠÑ€Ð¶"]):
        return "cap:automate-workflow"
    
    # ÐžÑ€Ð³Ð°Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¸ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð°Ð½Ðµ
    if any(word in s for word in ["Ð¾Ñ€Ð³Ð°Ð½Ð¸Ð·Ð¸Ñ€Ð°Ð¹", "Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð°Ð¹", "Ð³Ñ€Ð°Ñ„Ð¸Ðº", "schedule", "ÐµÐºÐ¸Ð¿", "Ñ€ÐµÑÑƒÑ€ÑÐ¸"]):
        return "cap:automate-workflow"
    if any(word in s for word in ["Ð»Ð¾ÐºÐ°Ñ†Ð¸Ð¸", "Ð¼ÑÑÑ‚Ð¾", "venue", "ÑÑ‚ÑƒÐ´Ð¸Ð¾"]):
        return "cap:research-web"
    
    # Ð¤Ð¸Ð½Ð°Ð½ÑÐ¸ Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·
    if any(word in s for word in ["Ð¸Ð·Ð¼ÐµÑ€Ð¸", "Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð°Ð¹ Ñ€ÐµÐ·ÑƒÐ»Ñ‚Ð°Ñ‚Ð¸", "Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸", "roi", "ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°"]):
        return "cap:text-summarize"
    
    # Default fallback Ð±Ð°Ð·Ð¸Ñ€Ð°Ð½ Ð½Ð° Ð½Ð°Ð¹-Ñ‡ÐµÑÑ‚Ð¸Ñ‚Ðµ ÐºÐ»ÑŽÑ‡Ð¾Ð²Ð¸ Ð´ÑƒÐ¼Ð¸
    if any(word in s for word in ["ÑÑŠÐ·Ð´Ð°Ð¹", "Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð°Ð¹", "Ð½Ð°Ð¿Ñ€Ð°Ð²Ð¸", "Ð¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´Ð¸"]):
        return "cap:text-explain"  # ÐÐ°Ð¹-ÑƒÐ½Ð¸Ð²ÐµÑ€ÑÐ°Ð»Ð½Ð° capability
    
    # ÐÐºÐ¾ Ð½Ðµ Ð¼Ð¾Ð¶ÐµÐ¼ Ð´Ð° Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸Ð¼ - Ð²Ñ€ÑŠÑ‰Ð°Ð¼Ðµ None
    return None

# =========================================================
#                           API
# =========================================================
def group_plan_items(plan: List[Dict]) -> List[Dict]:
    grouped: List[Dict] = []
    for item in plan:
        uniq = {}
        for t in item.get("tools", []):
            if t and t.get("name"):
                uniq[t["name"]] = t
        grouped.append({"title": item["task"], "tools": list(uniq.values())})
    return grouped


@router.post("/plan", response_model=PlanResponse)
def generate_plan(
    request: PlanRequest,
    db: Session = Depends(get_db),
    model: Optional[str] = Query(default=None, enum=SUPPORTED_MODELS),
):
    _ = get_all_ratings()  # Ð½ÐµÐ±Ð»Ð¾ÐºÐ¸Ñ€Ð°Ñ‰ backoff
    if not model:
        model = "llama3-70b-8192"

    # Ð¾ÑÐ¸Ð³ÑƒÑ€Ð¸ Ð¸Ð½Ð´ÐµÐºÑÐ¸
    if not tools_by_tag:
        build_tool_index(db)
    if (_faiss_index is None and _emb_matrix is None):
        build_semantic_index(db)

    goal = (request.user_goal or "").strip()

    # 1) ÐÐºÐ¾ Ðµ *learning* (Ð½Ð°Ð¿Ñ€. â€žScrum") â†’ 3 ÐºÐ°Ð½Ð¾Ð½Ð¸Ñ‡Ð½Ð¸ Ð¾Ð±Ð¾Ð±Ñ‰ÐµÐ½Ð¸ ÑÑ‚ÑŠÐ¿ÐºÐ¸
    if _is_learning_query(goal):
        plan, groups = _learning_plan(goal, db)
        return {"goal": goal, "plan": plan, "groups": groups}

    # 2) Ð˜Ð½Ð°Ñ‡Ðµ â€“ Ð¾Ð¿Ð¸Ñ‚Ð°Ð¹ Ñ‚ÐµÐ¼Ð¿Ð»ÐµÐ¹Ñ‚
    tpl = match_template(goal)
    if tpl:
        out: List[Dict] = []
        for (task, caps) in tpl["steps"]:
            candidates: List[AITool] = []
            for cap in caps:
                candidates += _cap_candidates(cap, db, per_cap=16)
            if not candidates:
                candidates = [t for (t, _s) in _semantic_candidates(task, top_k=16)]
            cap_for_rank = caps[0] if caps else None
            tools = re_rank_tools(
                candidates=candidates,
                goal=goal,
                step=task,
                cap=cap_for_rank,
                semantic_query=task,
                top_n=6,
                ensure_universal_top3=False,
                db=db,
            )
            tools = tools[:3] if len(tools) > 3 else tools
            if not tools:
                tools = [{"name": "ChatGPT", "link": "https://chat.openai.com/", "icon": None}]
            out.append({"task": task, "tools": tools})
        groups = group_plan_items(out)
        return {"goal": goal, "plan": out, "groups": groups}

    # 3) ÐÑÐ¼Ð° Ñ‚ÐµÐ¼Ð¿Ð»ÐµÐ¹Ñ‚ â†’ LLM Ð¼Ð°ÐºÑ€Ð¾â€‘ÑÑ‚ÑŠÐ¿ÐºÐ¸ (3â€“5), Ð½Ð¾ Ð½Ðµ Ð¼Ð¸ÐºÑ€Ð¾
    steps = _llm_steps(goal, model)
    plan: List[Dict] = []
    for step in steps:
        cap = map_to_capability(step)
        if cap:
            candidates = _cap_candidates(cap, db, per_cap=16)
        else:
            candidates = [t for (t, _s) in _semantic_candidates(step, top_k=16)]
        tools = re_rank_tools(
            candidates=candidates, goal=goal, step=step, cap=cap, semantic_query=step,
            top_n=6, ensure_universal_top3=False, db=db
        )
        tools = tools[:3] if len(tools) > 3 else tools
        if not tools:
            tools = [{"name": "ChatGPT", "link": "https://chat.openai.com/", "icon": None}]
        plan.append({"task": step, "tools": tools})
    groups = group_plan_items(plan)
    return {"goal": goal, "plan": plan, "groups": groups}